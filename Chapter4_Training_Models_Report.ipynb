{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadhilahmad11/Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow-Tugas-Machine-LearningW8-W16/blob/main/Chapter4_Training_Models_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66679eb8",
      "metadata": {
        "id": "66679eb8"
      },
      "source": [
        "\n",
        "# Chapter 4: Training Models  \n",
        "\n",
        "---\n",
        "\n",
        "## 1. Pendahuluan  \n",
        "\n",
        "Bab ini membahas teori dasar dan praktik pelatihan model Machine Learning. Fokus utama pada:  \n",
        "- Linear Regression (Normal Equation & Gradient Descent)  \n",
        "- Polynomial Regression  \n",
        "- Regularisasi (Ridge, Lasso, Elastic Net)  \n",
        "- Logistic Regression dan Softmax  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b42e75f1",
      "metadata": {
        "id": "b42e75f1"
      },
      "source": [
        "\n",
        "## 2. Linear Regression  \n",
        "\n",
        "### Persamaan model  \n",
        "\n",
        "$\n",
        "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\dots + \\theta_n x_n = \\theta^T x\n",
        "$\n",
        "\n",
        "### Normal Equation  \n",
        "\n",
        "Digunakan untuk menghitung parameter optimal secara langsung:  \n",
        "\n",
        "$\n",
        "\\theta = (X^T X)^{-1} X^T y\n",
        "$\n",
        "\n",
        "Contoh kode:\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "X_b = np.c_[np.ones((100, 1)), X]\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "```\n",
        "Hasil `theta_best` mendekati [4, 3].\n",
        "\n",
        "### Linear Regression dengan Scikit-Learn  \n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14df9ab6",
      "metadata": {
        "id": "14df9ab6"
      },
      "source": [
        "\n",
        "## 3. Gradient Descent  \n",
        "\n",
        "Tujuan: meminimalkan cost function (MSE):  \n",
        "\n",
        "$\n",
        "MSE(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} (\\theta^T x^{(i)} - y^{(i)})^2\n",
        "$\n",
        "\n",
        "Gradiennya:  \n",
        "\n",
        "$\n",
        "\\frac{\\partial MSE}{\\partial \\theta} = \\frac{2}{m} X^T (X \\theta - y)\n",
        "$\n",
        "\n",
        "### Stochastic Gradient Descent  \n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1)\n",
        "sgd_reg.fit(X, y.ravel())\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f84ce32d",
      "metadata": {
        "id": "f84ce32d"
      },
      "source": [
        "\n",
        "## 4. Polynomial Regression  \n",
        "\n",
        "Linear Regression pada fitur polinomial untuk menangkap hubungan non-linear.  \n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99d4db5e",
      "metadata": {
        "id": "99d4db5e"
      },
      "source": [
        "\n",
        "## 5. Regularisasi  \n",
        "\n",
        "### Ridge Regression  \n",
        "\n",
        "$\n",
        "J(\\theta) = MSE(\\theta) + \\alpha \\sum_{i=1}^n \\theta_i^2\n",
        "$\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
        "ridge_reg.fit(X, y)\n",
        "```\n",
        "\n",
        "### Lasso Regression  \n",
        "\n",
        "$\n",
        "J(\\theta) = MSE(\\theta) + \\alpha \\sum_{i=1}^n |\\theta_i|\n",
        "$\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "lasso_reg = Lasso(alpha=0.1)\n",
        "lasso_reg.fit(X, y)\n",
        "```\n",
        "\n",
        "### Elastic Net  \n",
        "\n",
        "$\n",
        "J(\\theta) = MSE(\\theta) + r \\alpha \\sum |\\theta_i| + \\frac{(1 - r)}{2} \\alpha \\sum \\theta_i^2\n",
        "$\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
        "elastic_net.fit(X, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b55534ca",
      "metadata": {
        "id": "b55534ca"
      },
      "source": [
        "\n",
        "## 6. Logistic Regression  \n",
        "\n",
        "Untuk klasifikasi biner:  \n",
        "\n",
        "$\n",
        "\\hat{p} = \\frac{1}{1 + e^{-\\theta^T x}}\n",
        "$\n",
        "\n",
        "Cost function:\n",
        "\n",
        "$\n",
        "J(\\theta) = -\\frac{1}{m} \\sum \\left[ y^{(i)} \\log(\\hat{p}^{(i)}) + (1 - y^{(i)}) \\log(1 - \\hat{p}^{(i)}) \\right]\n",
        "$\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import datasets\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris[\"data\"][:, (2, 3)]\n",
        "y = (iris[\"target\"] == 2).astype(int)\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bef0d50",
      "metadata": {
        "id": "4bef0d50"
      },
      "source": [
        "\n",
        "## 7. Softmax Regression  \n",
        "\n",
        "Untuk multiclass:  \n",
        "\n",
        "$\n",
        "p_k = \\frac{e^{s_k(x)}}{\\sum_j e^{s_j(x)}}\n",
        "$\n",
        "\n",
        "```python\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10)\n",
        "softmax_reg.fit(X, iris[\"target\"])\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}