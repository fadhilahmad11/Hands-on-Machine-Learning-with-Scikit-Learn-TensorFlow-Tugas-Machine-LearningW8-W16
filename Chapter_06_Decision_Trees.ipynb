{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadhilahmad11/Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow-Tugas-Machine-LearningW8-W16/blob/main/Chapter_06_Decision_Trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "073d29f1",
      "metadata": {
        "id": "073d29f1"
      },
      "source": [
        "\n",
        "# Chapter 6: Decision Trees  \n",
        "\n",
        "---\n",
        "\n",
        "## 1. Pendahuluan  \n",
        "\n",
        "Decision Tree adalah model Machine Learning yang sangat intuitif. Model ini membagi ruang fitur menjadi area-area dengan label yang sama (klasifikasi) atau nilai serupa (regresi).  \n",
        "Tree dibangun dengan mempartisi data menggunakan fitur yang memaksimalkan “purity” pada setiap node (contoh: Gini impurity atau entropy).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166c28dd",
      "metadata": {
        "id": "166c28dd"
      },
      "source": [
        "\n",
        "## 2. Decision Tree untuk Klasifikasi  \n",
        "\n",
        "Pada setiap node, algoritma memilih fitur dan threshold yang memisahkan data sebaik mungkin.  \n",
        "\n",
        "### Contoh kode:\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:]  # petal length & width\n",
        "y = iris.target\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(max_depth=2)\n",
        "tree_clf.fit(X, y)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a1d9230",
      "metadata": {
        "id": "6a1d9230"
      },
      "source": [
        "\n",
        "## 3. Fungsi Impurity  \n",
        "\n",
        "### Gini Impurity  \n",
        "\n",
        "$\n",
        "G_i = 1 - \\sum_{k=1}^n p_{i,k}^2\n",
        "$\n",
        "\n",
        "di mana:\n",
        "- $( p_{i,k} $) adalah proporsi sample dari kelas $( k $) pada node $( i $).\n",
        "- \\( n \\) adalah jumlah kelas.\n",
        "\n",
        "**Penjelasan:**  \n",
        "Gini Impurity mengukur probabilitas salah klasifikasi jika kita menebak label secara acak mengikuti distribusi label pada node itu.  \n",
        "Nilai Gini = 0 artinya node pure (hanya satu kelas).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ccc447",
      "metadata": {
        "id": "e7ccc447"
      },
      "source": [
        "\n",
        "### Entropy  \n",
        "\n",
        "$\n",
        "H_i = - \\sum_{k=1}^n p_{i,k} \\log_2 p_{i,k}\n",
        "$\n",
        "\n",
        "**Penjelasan:**  \n",
        "Entropy mengukur ketidakteraturan pada node.  \n",
        "- Entropy = 0 jika semua data pada node berasal dari satu kelas.\n",
        "- Entropy lebih tinggi jika distribusi kelas seimbang.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27c2a80f",
      "metadata": {
        "id": "27c2a80f"
      },
      "source": [
        "\n",
        "## 4. Decision Tree untuk Regresi  \n",
        "\n",
        "Decision Tree Regression memprediksi dengan rata-rata target di tiap leaf node. Tujuan splitting: meminimalkan MSE.\n",
        "\n",
        "$\n",
        "MSE = \\frac{1}{m} \\sum_{i=1}^m (y^{(i)} - \\hat{y})^2\n",
        "$\n",
        "\n",
        "**Penjelasan:**  \n",
        "MSE mengukur rata-rata kuadrat selisih antara nilai aktual dan prediksi. Tree memilih split yang meminimalkan MSE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780252ed",
      "metadata": {
        "id": "780252ed"
      },
      "source": [
        "\n",
        "## 5. Regularisasi pada Decision Tree  \n",
        "\n",
        "Decision Tree cenderung overfitting jika tidak dikontrol. Parameter untuk regularisasi:  \n",
        "- `max_depth`: membatasi kedalaman tree.  \n",
        "- `min_samples_split`: minimum sample untuk split node.  \n",
        "- `min_samples_leaf`: minimum sample pada leaf node.  \n",
        "- `max_leaf_nodes`: maksimum leaf node.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d32d1c",
      "metadata": {
        "id": "73d32d1c"
      },
      "source": [
        "\n",
        "## 6. Visualisasi Decision Tree  \n",
        "\n",
        "Tree dapat divisualisasikan untuk interpretasi:\n",
        "\n",
        "```python\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "    tree_clf,\n",
        "    out_file=None,\n",
        "    feature_names=iris.feature_names[2:],\n",
        "    class_names=iris.target_names,\n",
        "    rounded=True,\n",
        "    filled=True\n",
        ")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a964fa8e",
      "metadata": {
        "id": "a964fa8e"
      },
      "source": [
        "\n",
        "## 7. Kelebihan dan Kekurangan Decision Tree  \n",
        "\n",
        "**Kelebihan:**  \n",
        "- Mudah dipahami dan divisualisasikan.  \n",
        "- Tidak butuh scaling fitur.  \n",
        "- Bisa digunakan untuk data non-linear.\n",
        "\n",
        "**Kekurangan:**  \n",
        "- Mudah overfit pada data training.  \n",
        "- Sensitif terhadap perubahan data kecil.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}