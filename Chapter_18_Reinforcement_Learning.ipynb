{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadhilahmad11/Hands-on-Machine-Learning-with-Scikit-Learn-TensorFlow-Tugas-Machine-LearningW8-W16/blob/main/Chapter_18_Reinforcement_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 18: Reinforcement Learning  \n",
        "\n",
        "## 1. Pendahuluan  \n",
        "\n",
        "Reinforcement Learning (RL) adalah metode di mana agen belajar dengan berinteraksi dengan lingkungan untuk memaksimalkan reward kumulatif.  \n",
        "RL cocok untuk masalah seperti game, robotika, dan optimisasi sekuensial.\n",
        "\n",
        "## 2. Komponen RL  \n",
        "\n",
        "- **Agent**: entitas yang belajar dan bertindak.\n",
        "- **Environment**: dunia tempat agent beroperasi.\n",
        "- **State (s)**: representasi kondisi saat ini.\n",
        "- **Action (a)**: pilihan tindakan agent.\n",
        "- **Reward (r)**: feedback dari environment.\n",
        "- **Policy (π)**: strategi memilih aksi.\n",
        "\n",
        "## 3. Tujuan RL  \n",
        "\n",
        "Maksimalkan reward kumulatif:\n",
        "$\n",
        "G_t = \\sum_{k=0}^{\\infty} \\gamma^k r_{t+k+1}\n",
        "$\n",
        "\n",
        "- $( \\gamma $): discount factor (0 < γ ≤ 1)\n",
        "- $( r_t $): reward pada waktu t\n",
        "\n",
        "## 4. Q-Learning  \n",
        "\n",
        "Q-learning memperkirakan Q-value:\n",
        "$\n",
        "Q(s,a) = \\mathbb{E}[G_t | s_t = s, a_t = a]\n",
        "$\n",
        "\n",
        "Update rule:\n",
        "$\n",
        "Q(s,a) \\leftarrow Q(s,a) + \\alpha \\left[ r + \\gamma \\max_{a'} Q(s', a') - Q(s,a) \\right]\n",
        "$\n",
        "\n",
        "- $( \\alpha $): learning rate\n",
        "- $( s' $): next state\n",
        "\n",
        "\n",
        "## 5. Deep Q-Network (DQN)  \n",
        "\n",
        "Gunakan neural network untuk mendekati Q(s,a).  \n",
        "Stabilkan dengan:\n",
        "- **Experience replay**\n",
        "- **Target network**\n",
        "\n",
        "## 6. Policy Gradient  \n",
        "\n",
        "Alih-alih mempelajari Q, langsung optimalkan policy π:\n",
        "$\n",
        "\\nabla_\\theta J(\\theta) = \\mathbb{E} \\left[ \\nabla_\\theta \\log \\pi_\\theta(a|s) G_t \\right]\n",
        "$\n",
        "\n",
        "- $( \\theta $): parameter policy\n",
        "- $( J(\\theta) $): expected return\n",
        "\n"
      ],
      "metadata": {
        "id": "B4a-LuffQa-P"
      },
      "id": "B4a-LuffQa-P"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}